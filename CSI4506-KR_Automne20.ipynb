{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 8 - Représentation des connaissances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSI4506 Intelligence Artificielle  \n",
    "Automne 2020  \n",
    "Préparé par Julian Templeton, Caroline Barrière et Joel Muteba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***INTRODUCTION***:  \n",
    "\n",
    "Lors de la lecture de texte, comprendre le type d'entités avec le texte permet d'extraire des informations supplémentaires sur l'entité. Grâce à l'utilisation de la reconnaissance d'entités nommées (Named Entity Recognition, NER), nous sommes en mesure de déterminer si une entité est une personne, une organisation, un pays, ... Lors de l'exploration de texte en ligne, nous voyons aussi occasionnellement que les entités ont des liens cliquables vers des pages Web avec plus d'informations sur le entité. Il s'agit d'une forme d'amélioration du texte pour permettre aux lecteurs d'accéder facilement aux informations nécessaires pour comprendre chaque entité à partir du texte et de son contenu.\n",
    "\n",
    "Dans ce notebook, nous revisiterons l'ensemble de données d'actualités liées à Covid-19 du notebook 7 pour explorer comment nous pouvons améliorer la désambiguïsation du NER de spaCy et améliorer le texte des articles de presse grâce à l'utilisation du linking d'entités. Cela se fera en deux parties, où nous utiliserons d'abord la cohérence du texte pour la désambiguïsation NER, puis nous effectuons une amélioration du texte avec le linking d'entités.\n",
    "\n",
    "**Pour ce notebook, ne modifiez pas les définitions de fonction et assurez-vous d'utiliser la configuration qui vous est fournie ET ne soumettez que ce fichier, rien d'autre n'est nécessaire**.\n",
    "\n",
    "Ce notebook utilise des bibliothèques qui ont été utilisées dans les notebooks précédents, notamment spaCy et pandas. Rappelez-vous que si vous rencontrez des problèmes avec le chargement de «en» pour commenter cette ligne et décommenter la ligne de code incluse (de la même manière que vous avez pu le faire dans le notebook 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***DEVOIR***:  \n",
    "\n",
    "Parcourez le notebook en exécutant chaque cellule, une à la fois.\n",
    "Recherchez **(TO DO)** pour les tâches que vous devez effectuer. Ne modifiez pas le code en dehors des questions auxquelles vous êtes invité à répondre à moins que cela ne vous soit spécifiquement demandé. Une fois que vous avez terminé, signez le notebook (à la fin du notebook) et soumettez-le.\n",
    "\n",
    "*Le notebook sera noté le 30.\n",
    "Chaque **(TO DO)** est associé à un certain nombre de points.*\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting we will import every module that we will be using\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The core spacy object that will be used for tokenization, lemmatization, POS Tagging, ...\n",
    "# Note that this is specifically for the English language and requires the English package to be installed\n",
    "# via pip to work as intended.\n",
    "\n",
    "#sp = spacy.load('en')\n",
    "\n",
    "# If the above causes an error after installing the package described in (2), install the package described\n",
    "# in the Note section within the introduction and run this line of code instead of the above.\n",
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARTIE 1 - Cohérence du texte pour la désambiguïsation des entités nommées**  \n",
    "  \n",
    "Pour la première partie de ce notebook, nous utiliserons les modules de * spaCy * pour aider à éliminer l'ambiguïté du NER et à améliorer les résultats avec la cohérence du texte sur les documents du fichier inclus sur les articles de presse liés à Covid-19 de CBC News (le même fichier du notebook 7). Nous commencerons par examiner la désambiguïsation du NER effectuée par spaCy et penserons à quelques méthodes simples pour utiliser la cohérence des entités dans le texte afin d'améliorer potentiellement la désambiguïsation du NER.\n",
    "\n",
    "\n",
    "Comme pour le dernier notebook, l'ensemble de données est inclus avec ce notebook, mais les détails le concernant peuvent être trouvés [ici](https://www.kaggle.com/ryanxjhan/cbc-news-coronavirus-articles-march-26?select=news.csv). La première chose que nous allons faire, comme d'habitude, est de charger le fichier dans un dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>'More vital now:' Gay-straight alliances go vi...</td>\n",
       "      <td>2020-05-03 1:30</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>Lily Overacker and Laurell Pallot start each g...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/calgary/gay-str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Scientists aim to 'see' invisible transmission...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>Some researchers aim to learn more about how t...</td>\n",
       "      <td>This is an excerpt from Second Opinion, a week...</td>\n",
       "      <td>https://www.cbc.ca/news/technology/droplet-tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>['The Canadian Press']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-02 11:28</td>\n",
       "      <td>Canada's chief public health officer struck an...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>B.C. announces 26 new coronavirus cases, new c...</td>\n",
       "      <td>2020-05-02 18:45</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>B.C. provincial health officer Dr. Bonnie Henr...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/british-columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>['Senior Writer', 'Chris Arsenault Is A Senior...</td>\n",
       "      <td>Brazil has the most confirmed COVID-19 cases i...</td>\n",
       "      <td>2020-05-02 8:00</td>\n",
       "      <td>From describing coronavirus as a \"little flu,\"...</td>\n",
       "      <td>With infection rates spiralling, some big city...</td>\n",
       "      <td>https://www.cbc.ca/news/world/brazil-has-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>The latest on the coronavirus outbreak for May 1</td>\n",
       "      <td>2020-05-01 20:43</td>\n",
       "      <td>The latest on the coronavirus outbreak from CB...</td>\n",
       "      <td>Coronavirus Brief (CBC)  Canada is officiall...</td>\n",
       "      <td>https://www.cbc.ca/news/the-latest-on-the-coro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>['Cbc News']</td>\n",
       "      <td>Coronavirus: What's happening in Canada and ar...</td>\n",
       "      <td>2020-05-01 11:51</td>\n",
       "      <td>Nova Scotia announced Friday it is immediately...</td>\n",
       "      <td>The latest:  The lives behind the numbers: Wha...</td>\n",
       "      <td>https://www.cbc.ca/news/canada/coronavirus-cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>['Senior Writer', \"Adam Miller Is Senior Digit...</td>\n",
       "      <td>Did the WHO mishandle the global coronavirus p...</td>\n",
       "      <td>2020-04-30 8:00</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>The World Health Organization has come under f...</td>\n",
       "      <td>https://www.cbc.ca/news/health/coronavirus-who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>['Thomson Reuters']</td>\n",
       "      <td>Armed people in Michigan's legislature protest...</td>\n",
       "      <td>2020-04-30 21:37</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>Hundreds of protesters, some armed, gathered a...</td>\n",
       "      <td>https://www.cbc.ca/news/world/protesters-michi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                            authors  \\\n",
       "0          0                                                 []   \n",
       "1          1                                                 []   \n",
       "2          2                             ['The Canadian Press']   \n",
       "3          3                                                 []   \n",
       "4          4                                                 []   \n",
       "5          5  ['Senior Writer', 'Chris Arsenault Is A Senior...   \n",
       "6          6                                       ['Cbc News']   \n",
       "7          7                                       ['Cbc News']   \n",
       "8          8  ['Senior Writer', \"Adam Miller Is Senior Digit...   \n",
       "9          9                                ['Thomson Reuters']   \n",
       "\n",
       "                                               title      publish_date  \\\n",
       "0  'More vital now:' Gay-straight alliances go vi...   2020-05-03 1:30   \n",
       "1  Scientists aim to 'see' invisible transmission...   2020-05-02 8:00   \n",
       "2  Coronavirus: What's happening in Canada and ar...  2020-05-02 11:28   \n",
       "3  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "4  B.C. announces 26 new coronavirus cases, new c...  2020-05-02 18:45   \n",
       "5  Brazil has the most confirmed COVID-19 cases i...   2020-05-02 8:00   \n",
       "6   The latest on the coronavirus outbreak for May 1  2020-05-01 20:43   \n",
       "7  Coronavirus: What's happening in Canada and ar...  2020-05-01 11:51   \n",
       "8  Did the WHO mishandle the global coronavirus p...   2020-04-30 8:00   \n",
       "9  Armed people in Michigan's legislature protest...  2020-04-30 21:37   \n",
       "\n",
       "                                         description  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  Some researchers aim to learn more about how t...   \n",
       "2  Canada's chief public health officer struck an...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  From describing coronavirus as a \"little flu,\"...   \n",
       "6  The latest on the coronavirus outbreak from CB...   \n",
       "7  Nova Scotia announced Friday it is immediately...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Lily Overacker and Laurell Pallot start each g...   \n",
       "1  This is an excerpt from Second Opinion, a week...   \n",
       "2  The latest:  The lives behind the numbers: Wha...   \n",
       "3  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "4  B.C. provincial health officer Dr. Bonnie Henr...   \n",
       "5  With infection rates spiralling, some big city...   \n",
       "6    Coronavirus Brief (CBC)  Canada is officiall...   \n",
       "7  The latest:  The lives behind the numbers: Wha...   \n",
       "8  The World Health Organization has come under f...   \n",
       "9  Hundreds of protesters, some armed, gathered a...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.cbc.ca/news/canada/calgary/gay-str...  \n",
       "1  https://www.cbc.ca/news/technology/droplet-tra...  \n",
       "2  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "3  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "4  https://www.cbc.ca/news/canada/british-columbi...  \n",
       "5  https://www.cbc.ca/news/world/brazil-has-the-m...  \n",
       "6  https://www.cbc.ca/news/the-latest-on-the-coro...  \n",
       "7  https://www.cbc.ca/news/canada/coronavirus-cov...  \n",
       "8  https://www.cbc.ca/news/health/coronavirus-who...  \n",
       "9  https://www.cbc.ca/news/world/protesters-michi...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset, show top ten rows\n",
    "df = pd.read_csv(\"news.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le notebook précédent, lorsque nous avons exploré comment spaCy peut effectuer les différentes étapes de la pipeline TAL, nous avons vu qu'il était capable d'effectuer la reconnaissance d'entités nommées (NER). Vous trouverez ci-dessous le même exemple que nous avons vu dans le dernier notebook pour montrer comment nous pouvons accéder aux prédictions de type NER de spaCy pour les tokens dans un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Canada\" is a GPE\n",
      "\"at least two metres\" is a QUANTITY\n"
     ]
    }
   ],
   "source": [
    "# Same example from notebook 7, recall that we loop through the iterator found in the .ents property of a parsed sentence\n",
    "sentence_example = \"Government guidelines in Canada recommend that people stay at least two metres away from others as part of physical distancing measures to curb the spread of COVID-19.\"\n",
    "sentence_example_content = sp(sentence_example)\n",
    "# Loop through all tokens that contain a NER type and print the token along with the corresponding NER type\n",
    "for token in sentence_example_content.ents:\n",
    "    print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1**  \n",
    "\n",
    "Avant d'effectuer un NER avec cohérence de texte, vous explorerez d'abord comment spaCy effectue la désambiguïsation du NER. Dans le texte du ***second document*** (index 1) de notre corpus de documents, quels mots sont *PER* (spaCy utilise le type *PERSON*, plutôt que *PER*), *ORG* (Organisation) et *GPE* (entité géopolitique). Vous devez effectuer les opérations suivantes pour cette question:\n",
    "\n",
    "a) Imprimez chaque *PER*, *ORG* et *GPE* avec son type NER depuis spaCy.\n",
    "\n",
    "b) Toutes ces prédictions de type NER sont-elles correctes? Sinon, donnez trois exemples de sorties incorrectes.\n",
    "\n",
    "c) Est-ce que certains des problèmes avec les prédictions de type NER proviennent d'une étape antérieure dans la pipeline TAL qui est effectuée par spaCy? Décrivez le problème pour deux exemples de la sortie ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1 (a) - 2 points**  \n",
    "\n",
    "Imprimez chaque *PER*, *ORG* et *GPE* avec son type NER depuis spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"the World Health Organization\" is a ORG\n",
      "\"Touches\" is a ORG\n",
      "\"WHO\" is a ORG\n",
      "\"the Public Health Agency\" is a ORG\n",
      "\"W.F. Wells\" is a PERSON\n",
      "\"Harvard School of Public Health\" is a ORG\n",
      "\"Wells\" is a ORG\n",
      "\"Canada\" is a GPE\n",
      "\"Lydia Bourouiba\" is a PERSON\n",
      "\"the Fluid Dynamics of Disease Transmission Laboratory\" is a ORG\n",
      "\"the Massachusetts Institute of Technology\" is a ORG\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"Mark Loeb\" is a PERSON\n",
      "\"Hamilton\" is a PERSON\n",
      "\"McMaster University\" is a ORG\n",
      "\"RNA\" is a GPE\n",
      "\"Wuhan\" is a GPE\n",
      "\"China\" is a GPE\n",
      "\"Nebraska\" is a GPE\n",
      "\"Loeb\" is a PERSON\n",
      "\"Loeb\" is a PERSON\n",
      "\"Canada\" is a GPE\n",
      "\"Gary Moore/CBC\" is a PERSON\n",
      "\"Allison McGeer\" is a PERSON\n",
      "\"Sinai Health\" is a ORG\n",
      "\"Toronto\" is a GPE\n",
      "\"particles \" is a PERSON\n",
      "\"McGeer\" is a ORG\n",
      "\"McGeer\" is a PERSON\n",
      "\"Bourouiba\" is a GPE\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"Bourouiba/MIT/\" is a ORG\n",
      "\"Samira Mubareka\" is a PERSON\n",
      "\"Sunnybrook Hospital\" is a ORG\n",
      "\"Toronto\" is a GPE\n",
      "\"Bourouiba\" is a PERSON\n",
      "\"JAMA Insights\" is a ORG\n",
      "\"McMaster\" is a PERSON\n",
      "\"Loeb\" is a PERSON\n",
      "\"N95\" is a ORG\n",
      "\"U.S.\" is a GPE\n",
      "\"Justin Trudeau\" is a PERSON\n",
      "\"the New England Journal of Medicine\" is a ORG\n",
      "\"the U.S. National Institutes of Health\" is a ORG\n",
      "\"U.S. National Institutes of Health\" is a ORG\n",
      "\"Journal of the Royal Society Interface\" is a ORG\n",
      "\"U.S.\" is a GPE\n",
      "\"Singapore\" is a GPE\n",
      "\"N95\" is a ORG\n",
      "\"Gary S. Settles\" is a PERSON\n",
      "\"Penn State University/Journal of the Royal Society Interface\" is a ORG\n",
      "\"The World Health Organization\" is a ORG\n",
      "\"Los Angeles\" is a GPE\n",
      "\"Italy\" is a GPE\n",
      "\"Austria\" is a GPE\n"
     ]
    }
   ],
   "source": [
    "# Select the second document (index 1)\n",
    "doc = df[\"text\"][1]\n",
    "doc_content = sp(doc)\n",
    "for token in doc_content.ents : \n",
    "    if token.label_ == \"PERSON\" or token.label_ == \"ORG\" or token.label_ == \"GPE\"  :\n",
    "        print(\"\\\"\" + token.text + \"\\\" is a \" + token.label_ )\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1 (b) - 1 point**   \n",
    "Toutes ces prédictions de type NER sont-elles correctes? Sinon, donnez deux exemples de sorties incorrectes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non, elles ne sont pas toutes correctes. Exemple: \n",
    "1. Touches est considéré comme une ORG (alors que c'est un verbe)\n",
    "2. N95 est considéré comme un ORG (alors que c'est un type de masque)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q1 (c) - 2 points**   \n",
    "Est-ce que l'un des problèmes avec les prédictions de type NER provient d'une étape antérieure du pipeline NLP qui est effectuée par spaCy? Décrivez le problème pour deux exemples de la sortie ci-dessus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Touches est étiquetté comme étant un \"proper noun\" durant étiquettage des parties du discours.\n",
    "2. N95 est étiquetté comme étant un \"number\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que vous avez vu que spaCy NER ne fonctionne pas toujours correctement, nous allons essayer d'utiliser la cohérence du texte pour modifier les types de NER fournis par spaCy. En fait, spaCy affecte les types d'entités une phrase à la fois. Mais en regardant un document entier, et sachant que le texte est généralement cohérent, nous pouvons effectuer un post-traitement dans le module NER de spaCy et corriger certaines erreurs. Par texte cohérent, nous entendons, par exemple, que si une personne est mentionnée avec un nom particulier, par ex. *McGeer*, il y a de fortes chances que chaque fois que nous voyons *McGeer* dans le document, ce soit la même personne. Il est donc peu probable que *McGeer* soit une fois une personne et une fois une organisation. Ce n'est pas toujours vrai, mais c'est une hypothèse courante. Par conséquent, nous explorerons deux stratégies différentes pour utiliser la cohérence du texte pour post-traiter la sortie du module spaCy NER.\n",
    "\n",
    "La première stratégie (*explorée en Q2 / Q3*) est de trouver, parmi tous les types de NER assignés, lequel est le plus fréquent. Par exemple, l'entité *Bourouiba* s'est vu attribuer 1 fois GPE et 3 fois PERSON, donc ces informations peuvent être utilisées pour modifier le type GPE et le changer en PERSON.\n",
    "\n",
    "La deuxième stratégie (explorée à la Q4) est d'essayer de trouver une forme plus longue dans le texte. Puisque cette forme plus longue devrait être moins ambiguë, nous pouvons l'utiliser pour lever l'ambiguïté des formes plus courtes et plus ambiguës. Par exemple, *Lydia Bourouiba* apparaît dans le texte et se voit attribuer PERSONNE. Nous pouvons utiliser ces informations pour attribuer d'autres occurrences de la forme abrégée *Bourouiba* à également PERSONNE.\n",
    "\n",
    "Une fois que nous avons défini ces deux stratégies, elles peuvent être combinées de différentes manières. Ainsi, à la Q5, il vous est demandé de combiner les deux stratégies dans un composant de post-traitement pour le module spaCy NER. Bien sûr, utiliser cette cohérence de texte ne fonctionnera pas à chaque fois, et introduira malheureusement quelques erreurs ... Mais essayons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le reste de cette section, nous travaillerons avec le septième document du corpus (index 6). Ci-dessous, nous chargeons le document et explorons toutes les entités dans le document avec leur type NER correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document's text for the seventh document (index 6)\n",
    "doc = df[\"text\"][6]\n",
    "# Parse the text with spaCy\n",
    "doc_sp = sp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \"Coronavirus Brief\" is a ORG\n",
      "1: \"CBC\" is a ORG\n",
      "2: \"Canada\" is a GPE\n",
      "3: \"C.D. Howe\" is a PERSON\n",
      "4: \"Ontario\" is a GPE\n",
      "5: \"Monday\" is a DATE\n",
      "6: \"Alberta\" is a GPE\n",
      "7: \"first\" is a ORDINAL\n",
      "8: \"Saturday\" is a DATE\n",
      "9: \"Air Canada\" is a ORG\n",
      "10: \"Christmas\" is a DATE\n",
      "11: \"Canadians\" is a NORP\n",
      "12: \"more than $1.2 million\" is a MONEY\n",
      "13: \"England\" is a GPE\n",
      "14: \"Peter Cziborra/Reuters\" is a PERSON\n",
      "15: \"months\" is a DATE\n",
      "16: \"CBC\" is a ORG\n",
      "17: \"Andre Mayer\" is a PERSON\n",
      "18: \"Canada\" is a GPE\n",
      "19: \"19th-century\" is a DATE\n",
      "20: \"2013\" is a DATE\n",
      "21: \"Calgary\" is a GPE\n",
      "22: \"John Brown\" is a PERSON\n",
      "23: \"the University of Calgary\" is a ORG\n",
      "24: \"two-metre\" is a TIME\n",
      "25: \"Last week\" is a DATE\n",
      "26: \"Italian\" is a NORP\n",
      "27: \"Milan\" is a GPE\n",
      "28: \"35 kilometres\" is a QUANTITY\n",
      "29: \"Berlin\" is a GPE\n",
      "30: \"Budapest\" is a GPE\n",
      "31: \"Mexico City\" is a GPE\n",
      "32: \"Ahsan Habib\" is a PERSON\n",
      "33: \"Dalhousie University\" is a ORG\n",
      "34: \"U.S.\" is a GPE\n",
      "35: \"Atlanta\" is a GPE\n",
      "36: \"Chicago\" is a GPE\n",
      "37: \"Denver\" is a GPE\n",
      "38: \"Habib\" is a PERSON\n",
      "39: \"Brown\" is a PERSON\n",
      "40: \"Calgary\" is a GPE\n",
      "41: \"Housebrand\" is a ORG\n",
      "42: \"Zoom\" is a PERSON\n",
      "43: \"The National The At Issue\" is a WORK_OF_ART\n",
      "44: \"Quebec\" is a GPE\n",
      "45: \"Conservative\" is a NORP\n",
      "46: \"BRIEF Canada\" is a ORG\n",
      "47: \"C.D. Howe\" is a PERSON\n",
      "48: \"Canada\" is a GPE\n",
      "49: \"the C.D. Howe Institute's Business Cycle Council\" is a ORG\n",
      "50: \"today\" is a DATE\n",
      "51: \"Canada\" is a GPE\n",
      "52: \"February\" is a DATE\n",
      "53: \"one\" is a CARDINAL\n",
      "54: \"two\" is a CARDINAL\n",
      "55: \"three-month\" is a DATE\n",
      "56: \"two quarters\" is a DATE\n",
      "57: \"less than two months old\" is a DATE\n",
      "58: \"Canada\" is a GPE\n",
      "59: \"first\" is a ORDINAL\n",
      "60: \"Canada\" is a GPE\n",
      "61: \"2008\" is a DATE\n",
      "62: \"March\" is a DATE\n",
      "63: \"April\" is a DATE\n",
      "64: \"the entire month\" is a DATE\n",
      "65: \"Canada\" is a GPE\n",
      "66: \"Ontario\" is a GPE\n",
      "67: \"Monday\" is a DATE\n",
      "68: \"Alberta\" is a GPE\n",
      "69: \"Saturday\" is a DATE\n",
      "70: \"Ontario\" is a GPE\n",
      "71: \"today\" is a DATE\n",
      "72: \"Monday\" is a DATE\n",
      "73: \"Today\" is a DATE\n",
      "74: \"Doug Ford\" is a PERSON\n",
      "75: \"Alberta\" is a GPE\n",
      "76: \"Jason Kenney\" is a PERSON\n",
      "77: \"first\" is a ORDINAL\n",
      "78: \"Alberta\" is a GPE\n",
      "79: \"Saturday\" is a DATE\n",
      "80: \"mid-May\" is a DATE\n",
      "81: \"Kenney\" is a ORG\n",
      "82: \"Thursday\" is a DATE\n",
      "83: \"Monday\" is a DATE\n",
      "84: \"the end of the academic year\" is a DATE\n",
      "85: \"Kenney\" is a PERSON\n",
      "86: \"summer\" is a DATE\n",
      "87: \"Canada\" is a GPE\n",
      "88: \"Air Canada\" is a ORG\n",
      "89: \"Christmas\" is a DATE\n",
      "90: \"Air Canada\" is a ORG\n",
      "91: \"winter\" is a DATE\n",
      "92: \"Canadians\" is a NORP\n",
      "93: \"Tim Strauss\" is a PERSON\n",
      "94: \"Canadian\" is a NORP\n",
      "95: \"Air Canada\" is a ORG\n",
      "96: \"more than 90\" is a CARDINAL\n",
      "97: \"Canadian\" is a NORP\n",
      "98: \"today\" is a DATE\n",
      "99: \"North American\" is a NORP\n",
      "100: \"Air Canada\" is a ORG\n",
      "101: \"American Airlines\" is a ORG\n",
      "102: \"Transport Canada\" is a ORG\n",
      "103: \"two metres\" is a QUANTITY\n",
      "104: \"Air Canada\" is a ORG\n",
      "105: \"Christmas\" is a DATE\n",
      "106: \"Helane Becker\" is a PERSON\n",
      "107: \"first\" is a ORDINAL\n",
      "108: \"Canada\" is a GPE\n",
      "109: \"CBC News\" is a ORG\n",
      "110: \"covid@cbc.ca\" is a CARDINAL\n",
      "111: \"U.S.\" is a GPE\n",
      "112: \"U.S.\" is a GPE\n",
      "113: \"Anthony Fauci\" is a PERSON\n",
      "114: \"Canada\" is a GPE\n",
      "115: \"Health Canada\" is a ORG\n",
      "116: \"Health Canada\" is a ORG\n",
      "117: \"Gilead\" is a ORG\n",
      "118: \"CBC News\" is a ORG\n",
      "119: \"Gilead\" is a ORG\n",
      "120: \"Canada\" is a GPE\n",
      "121: \"Alberta\" is a GPE\n",
      "122: \"daily\" is a DATE\n",
      "123: \"Everly-Ann Toma\" is a FAC\n",
      "124: \"Grace Horsfall Couldwell\" is a ORG\n",
      "125: \"Paint\" is a ORG\n",
      "126: \"MJ\" is a PERSON\n",
      "127: \"Facebook\" is a ORG\n",
      "128: \"Alberta\" is a GPE\n",
      "129: \"MJ Stead\" is a PERSON\n",
      "130: \"Lori Toma\" is a PERSON\n",
      "131: \"Nancy Horsfall Couldwell\" is a PERSON\n",
      "132: \"Alta\" is a WORK_OF_ART\n",
      "133: \"MJ Stead\" is a PERSON\n",
      "134: \"Facebook\" is a ORG\n",
      "135: \"Paint\" is a ORG\n",
      "136: \"MJ\" is a ORG\n",
      "137: \"Facebook Live\" is a WORK_OF_ART\n",
      "138: \"20\" is a CARDINAL\n",
      "139: \"30\" is a CARDINAL\n",
      "140: \"more than 1,500\" is a CARDINAL\n",
      "141: \"more than one\" is a CARDINAL\n",
      "142: \"Two years ago\" is a DATE\n",
      "143: \"Stead\" is a PERSON\n",
      "144: \"100 days\" is a DATE\n",
      "145: \"Canada\" is a GPE\n",
      "146: \"covid@cbc.ca\" is a CARDINAL\n",
      "147: \"CBC News\" is a ORG\n",
      "148: \"daily\" is a DATE\n",
      "149: \"CBC News Network\" is a ORG\n",
      "150: \"CBC News Network\" is a ORG\n",
      "151: \"CBC\" is a ORG\n",
      "152: \"CBC News Network\" is a ORG\n",
      "153: \"CBC News\" is a ORG\n"
     ]
    }
   ],
   "source": [
    "# Display all entities from the text along with their index in the .ents iterator and the\n",
    "# corresponding NER type\n",
    "for i, token in enumerate(doc_sp.ents):\n",
    "    print(str(i) + \": \\\"\" + token.text + \"\\\" is a \" + token.label_ )\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q2 - 3 points**  \n",
    "Comme vous pouvez le voir dans les résultats, parfois la même entité s'est vu attribuer différents types d'entités (par exemple, dans le document pour Q1 *McGeer* était une fois ORG, une fois PERSON) puisque l'algorithme NER regarde phrase par phrase. Dans la fonction suivante, le but sera de trouver tous les types d'entités possibles affectés à une seule entité.\n",
    "\n",
    "Complétez la définition de la fonction *find_entity_types* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* (à partir de l'itérable *.ents* des entités) et une liste de toutes les entités spaCy définies par le paramètre *entity*.\n",
    "\n",
    "La fonction doit trouver toutes les entités du même nom que *entité* à partir des *entités* (la même forme de surface). Pour chaque correspondance entre les entités, ajoutez le type NER de l'entité de la liste au dictionnaire *type_counts* et suivez le nombre de fois où chaque type NER apparaît.\n",
    "\n",
    "Ex: type_counts \\[NER type\\] = nombre total de fois où le décompte apparaît"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entity_types(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, finds all entities from the list that match the specified\n",
    "    entity, but are of a different type.\n",
    "    \n",
    "    Returns the different NER types that have been classified for an entity and the count per NER type\n",
    "    as a dictionary with the keys as the NER type and the value as the count\n",
    "    '''\n",
    "    type_counts = { }\n",
    "    for token in entities :\n",
    "        if  token.text == entity.text:\n",
    "            if token.label_ in type_counts :\n",
    "                num = type_counts[token.label_]\n",
    "                num = num + 1\n",
    "                type_counts.update({token.label_ : num})\n",
    "            else:\n",
    "                type_counts.update({token.label_ : 1})\n",
    "    \n",
    "    return type_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible NER types for \"Kenney\" are {'ORG': 1, 'PERSON': 1}\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Kenney' \n",
    "# from the document loaded above\n",
    "print(\"All possible NER types for \\\"\" + doc_sp.ents[85].text + \"\\\" are \" + str(find_entity_types(doc_sp.ents[85], doc_sp.ents)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q3 - 2 points**  \n",
    "\n",
    "Dans la méthode précédente, *find_entity_types*, nous avons trouvé tous les types d'entités possibles pour une seule entité. Maintenant, nous voulons les utiliser pour trouver le type le plus courant. Si nous regardons à nouveau les résultats pour Q1, dans le cas de *McGeer*, c'est une égalité. Mais pour *Bourouiba*, il existe un type GPE et 3 types PERSON, donc le plus courant serait PERSON.\n",
    "\n",
    "Complétez la définition de la fonction *most_common_type* ci-dessous. Cette fonction accepte en entrée une entité spaCy spécifique définie par le paramètre *entity* (à partir de l'itérable *.ents* des entités) et une liste de toutes les entités spaCy définies par le paramètre *entity*.\n",
    "\n",
    "Remarque: vous pouvez régler les cas d'égalité à votre guise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "def most_common_type(entity, entities):\n",
    "    '''\n",
    "    Given a specific entity and a list of entities, find the most similar entities and assign the\n",
    "    NER type to entity based on the most common NER type assigned to entities of the same name (if there\n",
    "    is a tie, you decide how to handle this).\n",
    "    \n",
    "    Returns the most common NER type based on similar entities\n",
    "    '''\n",
    "    dict_entity = find_entity_types(entity, entities.ents)\n",
    "    max_key = max(dict_entity, key = dict_entity.get)\n",
    "    for i in range(len(entities.ents)):\n",
    "        if entities.ents[i].text == entity.text:\n",
    "            ents = list(entities.ents)\n",
    "            old_ent = ents[i]\n",
    "            new_ent = Span(entities, old_ent.start, old_ent.end, label = max_key)\n",
    "            ents[i] = new_ent\n",
    "            entities.ents = ents\n",
    "        \n",
    "    \n",
    "    return max_key\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common NER type to \"Kenney\" is ORG\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Kenney' \n",
    "# from the document loaded above\n",
    "print(\"The most common NER type to \\\"\" + doc_sp.ents[85].text + \"\\\" is \" + most_common_type(doc_sp.ents[85], doc_sp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q4 - 2 points**  \n",
    "\n",
    "Nous allons maintenant travailler avec une méthode légèrement plus sophistiquée. Nous travaillerons à nouveau avec les mêmes *entité* et paramètres *entités*, mais cette fois vous devrez attribuer à *entité* le type NER d'une autre entité dans l'itérateur *entities*.\n",
    "\n",
    "Plus précisément, vous devez parcourir les *entités* pour trouver une forme normalisée de *entité*. Dans ce scénario, toute entité contenant *entité* en tant que sous-chaîne sera considérée comme une sélection valide pour la forme normalisée (où l'entité sélectionnée n'a pas le même nom que *entité*). Si une forme normalisée est trouvée, retournez le type NER de cette entité, le nom de cette entité et l'entité elle-même.\n",
    "\n",
    "Ex: *CBC News Network* est la forme normalisée de *CBC*. Ainsi, si cette entité est trouvée, retournez le type NER de l'entité (*ORG*) et le nom de l'entité (*CBC News Network*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_normalized_form(entity, entities):\n",
    "    '''\n",
    "    Given an entity and a list of entities, search the list of entities for any token that\n",
    "    is does not have the exact same text as entity and assign entity that token's NER type\n",
    "    if entity is a substring of that token.\n",
    "    \n",
    "    Returns the empty string if no normalized forms are found and the NER type of the normalized form if it is found.\n",
    "    Also returns the name of the entity found, if any (along with the entity).\n",
    "    '''\n",
    "    # MAY BE DONE SO THAT THE LAST GETS ADDED INSTEAD, THIS IS FINE.\n",
    "    # Recall to return the three requested components (NER type, the text, and the actual entity)\n",
    "    for token in entities :\n",
    "        if token.text != entity.text:\n",
    "            result = token.text.find(entity.text)\n",
    "            if result != -1 :\n",
    "                return token.label_, token.text, entity\n",
    "    return \"\"\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PERSON', 'Jason Kenney', Kenney)\n",
      "('ORG', 'CBC News Network', CBC News)\n"
     ]
    }
   ],
   "source": [
    "# Test the above to find the result when checking for the types of the entity 'Kenney' \n",
    "# from the document loaded above\n",
    "print(assign_normalized_form(doc_sp.ents[85], doc_sp.ents))\n",
    "# Test the above to find the result when checking for the types of the entity 'CBC News' \n",
    "# from the document loaded above\n",
    "print(assign_normalized_form(doc_sp.ents[153], doc_sp.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5**  \n",
    "\n",
    "Maintenant que vous avez défini plusieurs algorithmes pour effectuer une désambiguïsation NER avec cohérence de texte, vous allez tester vos algorithmes et les utiliser pour définir une méthode légèrement plus robuste de désambiguïsation NER en combinant les techniques effectuées. Vous explorerez ensuite si ces techniques aident toujours à désambiguïser les NER.\n",
    "\n",
    "a) Revisitez le document qui a été utilisé à Q1 (index 1) et, pour chaque entité, récupérez la forme normalisée de l'entité (le cas échéant) et n'affichez que les formes normalisées avec leurs types NER dans le format suivant (seulement s'il y a est une forme normalisée renvoyée):\n",
    "\n",
    "&emsp; *Original_entity fait référence à Normalized_entity, et est un NER_Type_of_Normalized_Form*\n",
    "\n",
    "b) Définissez un algorithme plus robuste qui combine les algorithmes conçus dans les dernières questions. Cet algorithme doit accepter une entité spécifique et une liste d'entités comme entrée, rechercher la forme normalisée de l'entité spécifique (le cas échéant) et renvoyer un type NER pour la forme normalisée basée sur le type NER le plus courant pour cette entité. Si aucune forme normalisée n'est trouvée, l'algorithme doit continuer en utilisant l'entité spécifique. Vous devez également renvoyer le nom de la forme normalisée (ou de l'entité d'origine s'il n'y a pas de forme normalisée).\n",
    "\n",
    "c) Pour le septième document (index 6), exécutez l'algorithme défini en b) pour chaque entité, en imprimant ce qui suit pour chaque entité:\n",
    "\n",
    "&emsp; *Original_entity fait référence à Normalized_entity (si aucun, identique à l'original), et est un Most_common_NER_type_of_normalized_form*\n",
    "\n",
    "d) Est-ce que l'un des résultats obtenus en effectuant une désambiguïsation NER avec la cohérence du texte Q5 (c) semble problématique? Donnez un exemple de problème qui se produit avec nos approches et expliquez pourquoi ce problème se produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 (a) - 1 point**     \n",
    "\n",
    "a) Revisitez le document qui a été utilisé à Q1 (index 1) et, pour chaque entité, récupérez la forme normalisée de l'entité (le cas échéant) et n'affichez que les formes normalisées ainsi que leurs types NER dans le format suivant (seulement s'il y a est une forme normalisée renvoyée):\n",
    "\n",
    "&emsp; *Original_entity fait référence à Normalized_entity, et est un NER_Type_of_Normalized_Form*\n",
    "\n",
    "Par exemple \"Bourouiba fait référence à Lydia Bourouiba, et est une PERSONNE\" serait imprimé pour une entité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select document 2\n",
    "doc = df[\"text\"][1]\n",
    "sp_doc_test = sp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two metres fait reference a at least two metres , et est un QUANTITY.\n",
      "two fait reference a two metres , et est un QUANTITY.\n",
      "two metres fait reference a at least two metres , et est un QUANTITY.\n",
      "Wells fait reference a W.F. Wells , et est un PERSON.\n",
      "Bourouiba fait reference a Lydia Bourouiba , et est un PERSON.\n",
      "Loeb fait reference a Mark Loeb , et est un PERSON.\n",
      "Loeb fait reference a Mark Loeb , et est un PERSON.\n",
      "McGeer fait reference a Allison McGeer , et est un PERSON.\n",
      "McGeer fait reference a Allison McGeer , et est un PERSON.\n",
      "2 fait reference a 2 metres , et est un QUANTITY.\n",
      "Bourouiba fait reference a Lydia Bourouiba , et est un PERSON.\n",
      "Bourouiba fait reference a Lydia Bourouiba , et est un PERSON.\n",
      "Bourouiba fait reference a Lydia Bourouiba , et est un PERSON.\n",
      "two metres fait reference a at least two metres , et est un QUANTITY.\n",
      "two fait reference a two metres , et est un QUANTITY.\n",
      "two fait reference a two metres , et est un QUANTITY.\n",
      "Second fait reference a Second Opinion , et est un LAW.\n",
      "McMaster fait reference a McMaster University , et est un ORG.\n",
      "Loeb fait reference a Mark Loeb , et est un PERSON.\n",
      "U.S. fait reference a the U.S. National Institutes of Health , et est un ORG.\n",
      "U.S. National Institutes of Health fait reference a the U.S. National Institutes of Health , et est un ORG.\n",
      "Journal of the Royal Society Interface fait reference a Penn State University/Journal of the Royal Society Interface , et est un ORG.\n",
      "U.S. fait reference a the U.S. National Institutes of Health , et est un ORG.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Loop through and print the assigned phrase with the appropriate text\n",
    "# Example of the print statement structure (from document 1): Bourouiba refers to Lydia Bourouiba, and is a PERSON\n",
    "for token in sp_doc_test.ents:\n",
    "    if assign_normalized_form(token, sp_doc_test.ents) != \"\" :\n",
    "        n_entity_type , n_entity_name, original = assign_normalized_form(token, sp_doc_test.ents)\n",
    "        print(str(original) + \" fait reference a \" + str(n_entity_name) + \" , et est un \" + str(n_entity_type) +\".\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 (b) - 2 points**     \n",
    "\n",
    "b) Définissez un algorithme plus robuste qui combine les algorithmes conçus dans les dernières questions. Cet algorithme doit accepter une entité spécifique et une liste d'entités en entrée, rechercher la forme normalisée de l'entité spécifique (le cas échéant) et renvoyer un type NER pour la forme normalisée basée sur le type NER le plus courant pour cette entité. Si aucune forme normalisée n'est trouvée, l'algorithme doit continuer en utilisant l'entité spécifique. Vous devez également renvoyer le nom de la forme normalisée (ou de l'entité d'origine s'il n'y a pas de forme normalisée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-48-3ad1be3204d6>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-48-3ad1be3204d6>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    if len(dict_entity) > 0:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def normalized_most_common_type(entity, entities):\n",
    "    '''\n",
    "    Determine the normalized form of an entity (if any; if none just use the entity) and\n",
    "    return the most frequent NER type for that normalized form from a list of entities.\n",
    "    '''\n",
    "    # TODO (Recall to return the name and the NER type that is found\n",
    "    for token in entities:\n",
    "        if token.text != entity.text :            \n",
    "            result = token.text.find(entity.text)\n",
    "            if result != -1 :\n",
    "               \n",
    "    if len(dict_entity) > 0:\n",
    "        return max(dict_entity, key = dict_entity.get)\n",
    "    else:\n",
    "        return entity\n",
    "                    \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 (c) - 1 point**   \n",
    "\n",
    "c) Pour le septième document (index 6), exécutez l'algorithme défini en b) pour chaque entité, en imprimant ce qui suit pour chaque entité:\n",
    "\n",
    "&emsp; *Original_entity fait référence à Normalized_entity (si aucun, identique à l'original), et est un Most_common_NER_type_of_normalized_form* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document's text\n",
    "doc = df[\"text\"][6]\n",
    "sp_doc_test = sp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Loop through and print the assigned phrase with the appropriate text\n",
    "for token in sp_doc_test.ents:\n",
    "    n_entity = normalized_most_common_type(token, sp_doc_test.ents)\n",
    "    n_entity_type = n_entity.label_\n",
    "    print(token.text + \" fait reference a \" + n_entity.text + \" et est un \" + str(n_entity_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q5 (d) - 2 points**     \n",
    "\n",
    "d) Est-ce que l'un des résultats obtenus en effectuant une désambiguïsation NER avec la cohérence du texte Q5 (c) semble problématique? Donnez un exemple de problème qui se produit avec nos approches et expliquez pourquoi ce problème se produit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO ...   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PARTIE 2 - Linking d'entité / Amélioration du texte**  \n",
    "\n",
    "Pour la deuxième partie de ce notebook, nous explorerons comment nous pouvons améliorer le texte des documents. Dans ce scénario, nous améliorerons le texte en effectuant un linking d'entité. Cela signifie que nous allons essayer plusieurs méthodes pour relier les entités qui sont détectées par le NER de spaCy à une page Web active sur laquelle un lecteur peut cliquer pour obtenir plus d'informations sur l'entité. De nombreux sites Web, tels que Wikipedia, effectuent des linkings d'entités pour permettre d'obtenir plus de contexte lors de la lecture d'un document.\n",
    "\n",
    "Avant d'aller directement dans un exemple à travers le code, voici un exemple de la façon dont un texte sans linking d'entité se compare à un texte avec linking d'entité:\n",
    "\n",
    "Aucun linking d'entité:\n",
    "Pendant la pandémie, des villes américaines telles qu'Atlanta, Chicago et Denver ont apporté plusieurs ajustements à leurs systèmes de transport en commun.\n",
    "\n",
    "Avec linking d'entité:\n",
    "Pendant la pandémie, des villes américaines telles que <a href=\"http://en.wikipedia.org/wiki/Atlanta\"> Atlanta </a>, <a href = \"http://en.wikipedia.org/wiki / Chicago \"> Chicago </a> et <a href=\"http://en.wikipedia.org/wiki/Denver\"> Denver </a> ont apporté plusieurs ajustements à leurs systèmes de transport en commun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que vous allez concevoir plusieurs méthodes pour effectuer un linking d'entité simple, voici un exemple qui montre comment nous pouvons effectuer manuellement la linking d'entités sans aucune ressource. Cela montrera comment cela peut être effectué afin que vous puissiez utiliser et créer des ressources pour créer vous-même des algorithmes de linking d'entités simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_example = \"During the pandemic, U.S. cities such as Atlanta, Chicago and Denver have made several adjustments to their transit systems\"\n",
    "# Parse the example sentence\n",
    "text_sp = sp(sentence_example)\n",
    "# This will store the enhanced version of the text\n",
    "enhanced_text = sentence_example\n",
    "# Loop through the entities that spaCy has found and replace them as needed to be in expanded form \n",
    "for token in text_sp.ents:\n",
    "    if token.text == \"Atlanta\":\n",
    "        enhanced_text = enhanced_text.replace(token.text, \"<a href=\\\"http://en.wikipedia.org/wiki/Atlanta\\\">Atlanta</a>\")\n",
    "    elif token.text == \"Chicago\":\n",
    "        enhanced_text = enhanced_text.replace(token.text, \"<a href=\\\"http://en.wikipedia.org/wiki/Chicago\\\">Chicago</a>\")\n",
    "    elif token.text == \"Denver\":\n",
    "        enhanced_text = enhanced_text.replace(token.text, \"<a href=\\\"http://en.wikipedia.org/wiki/Denver\\\">Denver</a>\")\n",
    "    \n",
    "# Write the result as an HTML file (open to view the enhanced text!)\n",
    "with open(\"enhanced_example.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(enhanced_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ouvrant le fichier *Enhanced_example.html* qui se trouve maintenant dans le même répertoire que ce notebook, vous pourrez voir comment nous avons liés les entités du texte.\n",
    "\n",
    "Cela dit, le processus ci-dessus est assez pauvre. Il fallait indiquer manuellement les entités avec lesquelles travailler et l'URL pour y établir un lien. Ainsi, vous répondrez aux questions pour le reste de cette section où vous utilisez et/ou créez des ressources qui ont été assemblées manuellement pour lier des entités dans des méthodes plus générales/robustes. Il existe de nombreuses techniques de correspondance de chaînes différentes qui peuvent être utilisées pour aider à le linking d'entités, mais nous nous en tiendrons aux approches de base pour ce notebook.\n",
    "\n",
    "Dans la question suivante, vous commencerez à travailler avec des ressources externes. Ainsi, ci-dessous, nous chargeons le fichier *US_Cities.csv* à utiliser pour améliorer le texte avec les villes américaines dans la question suivante. Notez que chaque fichier contient deux colonnes; *Texte* et *URL*. *Texte* fait référence à un nom d'entité et *URL* fait référence à une *URL* correspondante qui fournit plus d'informations concernant le *Texte*. L'exemple ci-dessous montre comment ces fichiers doivent être chargés et sont accessibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City - https://en.wikipedia.org/wiki/New_York_City\n",
      "Los Angelas - https://en.wikipedia.org/wiki/Los_Angeles\n",
      "Chicago - https://en.wikipedia.org/wiki/Chicago\n",
      "Houston - https://en.wikipedia.org/wiki/Houston\n",
      "Phoenix - https://en.wikipedia.org/wiki/Phoenix,_Arizona\n",
      "Philadelphia - https://en.wikipedia.org/wiki/Philadelphia\n",
      "San Antonio - https://en.wikipedia.org/wiki/San_Antonio\n",
      "San Diego - https://en.wikipedia.org/wiki/San_Diego\n",
      "Dallas - https://en.wikipedia.org/wiki/Dallas\n",
      "San Jose - https://en.wikipedia.org/wiki/San_Jose,_California\n",
      "Austin - https://en.wikipedia.org/wiki/Austin,_Texas\n",
      "Jacksonville - https://en.wikipedia.org/wiki/Jacksonville,_Florida\n",
      "Fort Worth - https://en.wikipedia.org/wiki/Fort_Worth,_Texas\n",
      "Columbus - https://en.wikipedia.org/wiki/Columbus,_Ohio\n",
      "Charlotte - https://en.wikipedia.org/wiki/Charlotte,_North_Carolina\n",
      "San Francisco - https://en.wikipedia.org/wiki/San_Francisco\n",
      "Indianapolis - https://en.wikipedia.org/wiki/Indianapolis\n",
      "Seattle - https://en.wikipedia.org/wiki/Seattle\n",
      "Denver - https://en.wikipedia.org/wiki/Denver\n",
      "Washington - https://en.wikipedia.org/wiki/Washington,_D.C.\n",
      "Boston - https://en.wikipedia.org/wiki/Boston\n",
      "El Paso - https://en.wikipedia.org/wiki/El_Paso,_Texas\n",
      "Nashville - https://en.wikipedia.org/wiki/Nashville,_Tennessee\n",
      "Detroit - https://en.wikipedia.org/wiki/Detroit\n",
      "Oklahoma City - https://en.wikipedia.org/wiki/Oklahoma_City\n",
      "Atlanta - https://en.wikipedia.org/wiki/Atlanta\n"
     ]
    }
   ],
   "source": [
    "# Start with the string match approach (exact match)\n",
    "# File content extracted from https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\n",
    "df_cities = pd.read_csv(\"US_Cities.csv\")\n",
    "# Print the Text and URL from each row, showcasing how to loop through the contents \n",
    "for i, row in df_cities.iterrows():\n",
    "    print(row[\"Text\"] + \" - \" + row[\"URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q6 - 3 points**  \n",
    "\n",
    "Complétez la fonction *enhan_text_with_resource* ci-dessous. Il reçoit le texte du document via *document_text*, le dataframe de la ressource externe pour améliorer le texte avec comme *resource_df*, et le nom du fichier dans lequel vous allez sortir les résultats (un fichier .html) comme *filename*.\n",
    "\n",
    "Cette fonction analyse le texte du document et remplace toutes les *entités* (.ents) trouvées dans le texte par:\n",
    "<a href=\\\"Some URL\">Texte d'entité</a\\>\n",
    "\n",
    "Après avoir amélioré le texte avec le linking d'entité, nous écrivons le texte amélioré dans un fichier html et renvoyons le texte amélioré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_text_with_resource(document_text, resource_df, filename):\n",
    "    '''\n",
    "    With a resource and document's text, enhance any entity found in the resource by linking the entity to\n",
    "    the appropriate webpage.\n",
    "    Write the file to the appropriate filename and return the enhanced text\n",
    "    '''\n",
    "   \n",
    "    enhanced_text = document_text\n",
    "    enhanced_list = []\n",
    "    hyperlink_format = '<a href=\"{link}\">{text}</a>'\n",
    "    # TODO: Parse the document with spaCy\n",
    "    sp_content = sp(document_text)\n",
    "    # TODO: Go through the entities and edit the document's text accordingly\n",
    "    for token in sp_content.ents:\n",
    "        for i, row in resource_df.iterrows():\n",
    "            var1 = row[\"URL\"]\n",
    "            var2 = token.text\n",
    "            if token.text == row[\"Text\"] and token.text not in enhanced_list:\n",
    "                               \n",
    "                \n",
    "                enhanced_text = enhanced_text.replace(token.text, hyperlink_format.format(link = var1, text =var2 ))\n",
    "                enhanced_list.append(token.text)\n",
    "                break;\n",
    "                \n",
    "    \n",
    "        \n",
    "        \n",
    "    # Note: Be sure to not duplicate your enhancementes\n",
    "    \n",
    "    # Write the result as an HTML file\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(enhanced_text)\n",
    "        f.close()\n",
    "    return enhanced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://foo/bar\"\\>linky text</a>\n"
     ]
    }
   ],
   "source": [
    "hyperlink_format = '<a href=\\\"{link}\"\\>{text}</a>'\n",
    "print(hyperlink_format.format(link = \"http://foo/bar\" , text = \"linky text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q7 - 3 points**  \n",
    "\n",
    "Grâce à l'algorithme d'amélioration du texte conçu (*enhan_text_with_resource*), vous allez maintenant tester la fonctionnalité lors de l'exécution de l'algorithme avec trois ressources différentes. Vous testerez l'algorithme pour chaque document déjà chargé dans la cellule de code et exécuterez les algorithmes avec les trois ressources suivantes:\n",
    "\n",
    "1) Un fichier contenant plusieurs villes américaines: *US_Cities.csv*\n",
    "\n",
    "2) Un fichier contenant toutes les provinces du Canada: *Canada_Provinces.csv*\n",
    "\n",
    "3) Un fichier contenant plusieurs universités canadiennes: *Canada_Universities.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the text for the document below with the US cities\n",
    "doc = df[\"text\"][6]\n",
    "\n",
    "# TODO ...\n",
    "enhanced_text_6 = enhance_text_with_resource(doc, df_cities, \"enhanced_ex_6.html\")\n",
    "\n",
    "\n",
    "# Enhance the text for the document below with the Canadian provinces\n",
    "# File extracted from https://en.wikipedia.org/wiki/Provinces_and_territories_of_Canada\n",
    "doc = df[\"text\"][53]\n",
    "df_provinces = pd.read_csv(\"Canada_Provinces.csv\")\n",
    "enhanced_text_53 = enhance_text_with_resource(doc, df_provinces,  \"enhanced_ex_53.html\")\n",
    "\n",
    "\n",
    "# Enhance the text for the document below with the Canadian universities\n",
    "# File extracted from https://en.wikipedia.org/wiki/List_of_universities_in_Canada\n",
    "doc = df[\"text\"][53]\n",
    "df_universities = pd.read_csv(\"Canada_Universities.csv\")\n",
    "enhanced_text_53_part2 = enhance_text_with_resource(doc, df_universities,  \"enhanced_ex_53_part2.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, si vous ouvrez les fichiers HTML enregistrés, vous devriez constater que les mots qui apparaissent dans le texte et la ressource sont désormais directement liés aux informations pertinentes pour cette entité. Nous serions également en mesure d'améliorer un document avec de nombreuses ressources pour relier autant d'entités que possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q8 - 2 points**  \n",
    "Parcourez les textes améliorés générés par vos tests dans Q7. Voyez-vous des universités qui ne sont pas liées lors de l'utilisation de la ressource universitaire? Pourquoi? Utilisez la cellule de code ci-dessous pour afficher tout ce que vous pourriez avoir besoin d'étudier (si vous n'avez rien remarqué des sorties précédentes) et répondez à la question dans la démarque sous cette cellule de code.\n",
    "\n",
    "Remarque: pour le savoir, vous devez parcourir les fichiers .csv et le texte lui-même (à la fois le texte initial et la détection d'entité de spaCy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look through any outputs that may seem off to help understand why (if not already known)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO ...    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q9 - 2 points**  \n",
    "Nous allons maintenant combiner une partie du travail effectué dans la partie 1 de ce notebook avec le travail effectué dans cette partie du notebook. Plus précisément, nous effectuerons une validation de type NER pour nous assurer que lorsque nous améliorons du texte avec une ressource, elle n'améliorera que les entités du type NER correct. Par exemple, lorsque nous utilisons la ressource des villes ou des provinces, assurez-vous que l'entité que nous examinons est classée comme GPE avant de l'étendre. Le même concept s'applique aux universités, qui devraient être classées comme ORG.\n",
    "\n",
    "Copiez votre définition de la fonction *enhan_text_with_resource*, étendez-la pour accepter également un type NER comme entrée (ex: *PERSON*, *ORG*, ...) et assurez-vous que l'amélioration du texte ne se produit que si *au moins une entité avec la même forme de surface* du document contient le même type NER que celui fourni au paramètre d'entrée. Cette nouvelle fonction est nommée *enhan_text_with_resource_and_type*.\n",
    "\n",
    "*NOTE (vous pouvez ignorer - juste pour plus d'informations):* En réalité, nous aimerions que ce soit défini de telle sorte que seule une entité d'un type spécifié ait son ensemble de tokens correspondant dans le texte à lier à la ressource. Cependant, ce processus peut être délicat car la logique impliquera de créer des indicateurs dans le texte pour savoir quelles entités ont déjà été vérifiées (ex: si *Nova Scotia* apparaît deux fois dans le texte, chaque instance avec son propre type NER, alors nous avons besoin pour connaître l'ensemble des tokens que nous éditons pour chacune des entités). Ainsi, vous devez uniquement vous assurer que si au moins une entité de la même forme de surface contient le type NER et se trouve dans le texte, toutes les instances de ces entités sont mises à jour. Si une ressource contient les entités dans le texte, mais qu'elles sont toutes d'un type différent, ignorez-les. Vous êtes libre de mettre en œuvre la méthode la plus robuste détaillée ci-dessus si vous le souhaitez, mais il est recommandé d'appliquer l'approche la plus simpliste que demande la question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_text_with_resource_and_type(document_text, resource_df, filename, NER_type):\n",
    "    '''\n",
    "    With a NER type, a resource and document's text, enhance any entity found in the resource by linking the entity to\n",
    "    the appropriate webpage if at least one surface form contains the specified NER type.\n",
    "    Write the file to the appropriate filename and return the enhanced text\n",
    "    '''\n",
    "    enhanced_text = document_text\n",
    "    enhanced_list = []\n",
    "    hyperlink_format = '<a href=\"{link}\">{text}</a>'\n",
    "    # TODO: Parse the document with spaCy\n",
    "    sp_content = sp(document_text)\n",
    "    # TODO: Go through the entities and edit the document's text accordingly\n",
    "    for token in sp_content.ents:\n",
    "        for i, row in resource_df.iterrows():\n",
    "            var1 = row[\"URL\"]\n",
    "            var2 = token.text\n",
    "            if token.text == row[\"Text\"] and token.text not in enhanced_list and token.label_ == NER_type:\n",
    "                               \n",
    "                \n",
    "                enhanced_text = enhanced_text.replace(token.text, hyperlink_format.format(link = var1, text =var2 ))\n",
    "                enhanced_list.append(token.text)\n",
    "                break;\n",
    "                \n",
    "    # TODO ...\n",
    "    # Write the result as an HTML file\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(enhanced_text)\n",
    "        f.close()\n",
    "    return enhanced_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(TO DO) Q10 - 2 points**  \n",
    "Refaites les tests effectués en Q7 avec la fonction *enhan_text_with_resource* nouvellement définie. Assurez-vous d'utiliser le type NER approprié en fonction de la ressource utilisée pour le linking autorisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the text for the document below with the US cities\n",
    "doc = df[\"text\"][6]\n",
    "enhanced_text_and_type_6 = enhance_text_with_resource_and_type(doc, df_cities, \"enhanced_type_ex_6.html\", \"GPE\")\n",
    "\n",
    "\n",
    "# Enhance the text for the document below with the Canadian provinces\n",
    "# File extracted from https://en.wikipedia.org/wiki/Provinces_and_territories_of_Canada\n",
    "doc = df[\"text\"][53]\n",
    "enhanced_text_and_type_53 = enhance_text_with_resource_and_type(doc, df_provinces,  \"enhanced_type_ex_53.html\", \"GPE\")\n",
    "# Enhance the text for the document below with the Canadian universities\n",
    "# File extracted from https://en.wikipedia.org/wiki/List_of_universities_in_Canada\n",
    "doc = df[\"text\"][53]\n",
    "enhanced_text_and_type_53_part2 = enhance_text_with_resource_and_type(doc, df_universities,  \"enhanced_type_ex_53_part2.html\", \"ORG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SIGNATURE:***\n",
    "Mon nom est --------Bhavika Sewpal------------------.\n",
    "Mon numéro d'étudiant est ----300089940-------------.\n",
    "J'atteste être l'auteur de cette mission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
